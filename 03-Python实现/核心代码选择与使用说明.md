# Voice Memory - æ ¸å¿ƒä»£ç é€‰æ‹©ä¸ä½¿ç”¨è¯´æ˜

**ç‰ˆæœ¬ï¼š** v0.1
**æ—¥æœŸï¼š** 2025-12-29
**çŠ¶æ€ï¼š** æŠ€æœ¯å®ç°æŒ‡å—

---

## ç›®å½•

1. [é¡¹ç›®ç»“æ„](#ä¸€é¡¹ç›®ç»“æ„)
2. [æ ¸å¿ƒä¾èµ–åº“](#äºŒæ ¸å¿ƒä¾èµ–åº“)
3. [å”¤é†’è¯æ£€æµ‹](#ä¸‰å”¤é†’è¯æ£€æµ‹)
4. [è¯­éŸ³è½¬æ–‡å­—](#å››è¯­éŸ³è½¬æ–‡å­—)
5. [æ–‡å­—è½¬è¯­éŸ³](#äº”æ–‡å­—è½¬è¯­éŸ³)
6. [AIå¯¹è¯](#å…­aiå¯¹è¯)
7. [è®°å¿†å­˜å‚¨](#ä¸ƒè®°å¿†å­˜å‚¨)
8. [å®Œæ•´ç¤ºä¾‹](#å…«å®Œæ•´ç¤ºä¾‹)

---

## ä¸€ã€é¡¹ç›®ç»“æ„

```
voice-memory/
â”œâ”€â”€ backend/                 # Pythonåç«¯æœåŠ¡
â”‚   â”œâ”€â”€ core/               # æ ¸å¿ƒé€»è¾‘
â”‚   â”‚   â”œâ”€â”€ wake_word.py   # å”¤é†’è¯æ£€æµ‹
â”‚   â”‚   â”œâ”€â”€ stt.py         # è¯­éŸ³è½¬æ–‡å­—
â”‚   â”‚   â”œâ”€â”€ tts.py         # æ–‡å­—è½¬è¯­éŸ³
â”‚   â”‚   â”œâ”€â”€ ai_client.py   # AIå¯¹è¯å®¢æˆ·ç«¯
â”‚   â”‚   â””â”€â”€ memory.py      # è®°å¿†å­˜å‚¨
â”‚   â”œâ”€â”€ api/                # FastAPIæ¥å£
â”‚   â”‚   â””â”€â”€ main.py        # APIå…¥å£
â”‚   â”œâ”€â”€ models/             # æ•°æ®æ¨¡å‹
â”‚   â””â”€â”€ config/             # é…ç½®æ–‡ä»¶
â”‚
â”œâ”€â”€ clients/                # å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ macos/             # macOS App
â”‚   â”‚   â””â”€â”€ VoiceMemory/
â”‚   â”‚       â”œâ”€â”€ AppDelegate.swift
â”‚   â”‚       â”œâ”€â”€ VoiceManager.swift
â”‚   â”‚       â””â”€â”€ Views/
â”‚   â”‚
â”‚   â””â”€â”€ terminal/          # Terminal CLI
â”‚       â””â”€â”€ vm.py
â”‚
â”œâ”€â”€ storage/               # æœ¬åœ°å­˜å‚¨
â”‚   â”œâ”€â”€ markdown/          # Markdownæ–‡ä»¶
â”‚   â””â”€â”€ memory.db          # SQLiteæ•°æ®åº“
â”‚
â”œâ”€â”€ tests/                 # æµ‹è¯•
â”œâ”€â”€ scripts/               # å·¥å…·è„šæœ¬
â””â”€â”€ requirements.txt       # Pythonä¾èµ–
```

---

## äºŒã€æ ¸å¿ƒä¾èµ–åº“

### 2.1 Pythonä¾èµ–

```txt
# requirements.txt

# Webæ¡†æ¶
fastapi==0.100.0
uvicorn[standard]==0.23.0
pydantic==2.0.0

# AIæœåŠ¡
anthropic==0.18.0
openai==1.3.0

# è¯­éŸ³å¤„ç†
pvporcupine==3.0.0
pyaudio==0.2.13
faster-whisper==1.0.0

# å­˜å‚¨
sqlalchemy==2.0.0
chromadb==0.4.0

# å·¥å…·
python-dotenv==1.0.0
typer==0.9.0
rich==13.0.0
```

### 2.2 Swiftä¾èµ–ï¼ˆmacOSï¼‰

```swift
// Package.swift

dependencies: [
    .package(url: "https://github.com/Picovoice/porcupine.git", from: "3.0.0"),
    .package(url: "https://github.com/openai/openai-swift", from: "1.0.0"),
]
```

---

## ä¸‰ã€å”¤é†’è¯æ£€æµ‹

### 3.1 é€‰æ‹©ï¼šPicovoice Porcupine

**é€‰æ‹©ç†ç”±ï¼š**
1. âœ… å‡†ç¡®åº¦é«˜ï¼ˆ91%+ï¼‰
2. âœ… ä½å»¶è¿Ÿï¼ˆ<100msï¼‰
3. âœ… è·¨å¹³å°æ”¯æŒ
4. âœ… å…è´¹ç‰ˆå¯ç”¨ï¼ˆä¸ªäºº/éå•†ä¸šï¼‰

**ç¼ºç‚¹ï¼š**
- âŒ å•†ä¸šæˆæƒè´µï¼ˆ$6,000+ï¼‰
- âŒ è‡ªå®šä¹‰è¯éœ€åœ¨çº¿è®­ç»ƒ

**å¤‡ç”¨æ–¹æ¡ˆï¼š** OpenWakeWordï¼ˆå¼€æºå…è´¹ï¼‰

### 3.2 å®‰è£…é…ç½®

```bash
# å®‰è£…Porcupine
pip install pvporcupine

# è·å–Access Keyï¼ˆå…è´¹ï¼‰
# è®¿é—®ï¼šhttps://picovoice.ai/
```

### 3.3 æ ¸å¿ƒä»£ç 

```python
# core/wake_word.py

import pvporcupine
import pyaudio
import struct
from typing import Optional, Callable

class WakeWordDetector:
    """å”¤é†’è¯æ£€æµ‹å™¨"""

    def __init__(
        self,
        access_key: str,
        keyword_path: str,
        sensitivity: float = 0.5,
        on_detected: Optional[Callable] = None
    ):
        """
        åˆå§‹åŒ–å”¤é†’è¯æ£€æµ‹å™¨

        Args:
            access_key: Picovoice Access Key
            keyword_path: è‡ªå®šä¹‰å”¤é†’è¯.ppnæ–‡ä»¶è·¯å¾„
            sensitivity: æ£€æµ‹çµæ•åº¦ï¼ˆ0-1ï¼‰
            on_detected: æ£€æµ‹åˆ°å”¤é†’è¯æ—¶çš„å›è°ƒ
        """
        self.porcupine = pvporcupine.create(
            access_key=access_key,
            keyword_paths=[keyword_path],
            sensitivities=[sensitivity]
        )

        self.audio = pyaudio.PyAudio()
        self.stream = None
        self.on_detected = on_detected
        self.is_running = False

    def start(self):
        """å¼€å§‹ç›‘å¬"""
        self.stream = self.audio.open(
            rate=self.porcupine.sample_rate,
            channels=1,
            format=pyaudio.paInt16,
            input=True,
            frames_per_buffer=self.porcupine.frame_length
        )
        self.is_running = True

    def stop(self):
        """åœæ­¢ç›‘å¬"""
        self.is_running = False
        if self.stream:
            self.stream.close()
            self.stream = None

    def listen(self):
        """
        æŒç»­ç›‘å¬å”¤é†’è¯ï¼ˆé˜»å¡ï¼‰

        Returns:
            bool: æ˜¯å¦æ£€æµ‹åˆ°å”¤é†’è¯
        """
        if not self.stream:
            raise RuntimeError("Stream not started. Call start() first.")

        try:
            while self.is_running:
                pcm = self.stream.read(self.porcupine.frame_length, exception_on_overflow=False)
                pcm = struct.unpack_from("h" * self.porcupine.frame_length, pcm)

                keyword_index = self.porcupine.process(pcm)

                if keyword_index >= 0:
                    if self.on_detected:
                        self.on_detected()
                    return True

        except KeyboardInterrupt:
            return False
        finally:
            self.stop()

    def listen_async(self):
        """å¼‚æ­¥ç›‘å¬ï¼ˆéé˜»å¡ï¼‰"""
        import threading
        thread = threading.Thread(target=self.listen)
        thread.daemon = True
        thread.start()
        return thread

    def __del__(self):
        """æ¸…ç†èµ„æº"""
        self.stop()
        self.audio.terminate()
        if self.porcupine:
            self.porcupine.delete()
```

### 3.4 ä½¿ç”¨ç¤ºä¾‹

```python
import os
from core.wake_word import WakeWordDetector

# é…ç½®
ACCESS_KEY = os.getenv("PICOVOICE_ACCESS_KEY")
KEYWORD_PATH = "wake_words/memory.ppn"  # è‡ªå®šä¹‰å”¤é†’è¯

def on_wake_word_detected():
    print("ğŸ¤ æ£€æµ‹åˆ°å”¤é†’è¯ï¼å¼€å§‹å¯¹è¯...")

# åˆ›å»ºæ£€æµ‹å™¨
detector = WakeWordDetector(
    access_key=ACCESS_KEY,
    keyword_path=KEYWORD_PATH,
    sensitivity=0.5,
    on_detected=on_wake_word_detected
)

# å¼€å§‹ç›‘å¬
detector.start()

# å¼‚æ­¥ç›‘å¬
detector.listen_async()

# ä¸»çº¿ç¨‹ç»§ç»­åšå…¶ä»–äº‹æƒ…
while True:
    # ... å…¶ä»–é€»è¾‘
    pass
```

---

## å››ã€è¯­éŸ³è½¬æ–‡å­—

### 4.1 é€‰æ‹©ï¼šOpenAI Whisper API

**é€‰æ‹©ç†ç”±ï¼š**
1. âœ… å‡†ç¡®åº¦æœ€é«˜ï¼ˆ7.6% WERï¼‰
2. âœ… 99ç§è¯­è¨€æ”¯æŒ
3. âœ… ç®€å•æ˜“ç”¨
4. âœ… å¿«é€Ÿè¿­ä»£

**ç¼ºç‚¹ï¼š**
- âŒ éšç§é¡¾è™‘ï¼ˆéŸ³é¢‘ä¸Šä¼ ï¼‰
- âŒ ä¾èµ–ç½‘ç»œ
- âŒ æˆæœ¬ç´¯ç§¯

**å¤‡ç”¨æ–¹æ¡ˆï¼š** faster-whisperï¼ˆæœ¬åœ°éƒ¨ç½²ï¼‰

### 4.2 æ ¸å¿ƒä»£ç 

```python
# core/stt.py

import os
import tempfile
from typing import Optional
from openai import OpenAI

class SpeechToText:
    """è¯­éŸ³è½¬æ–‡å­—ï¼ˆSTTï¼‰"""

    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–STTæœåŠ¡

        Args:
            api_key: OpenAI API Keyï¼ˆé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
        """
        self.client = OpenAI(api_key=api_key or os.getenv("OPENAI_API_KEY"))
        self.model = "whisper-1"

    def transcribe(
        self,
        audio_data: bytes,
        language: str = "zh",
        prompt: Optional[str] = None,
        response_format: str = "text"
    ) -> dict:
        """
        è½¬å†™éŸ³é¢‘ä¸ºæ–‡æœ¬

        Args:
            audio_data: éŸ³é¢‘æ•°æ®ï¼ˆbytesï¼‰
            language: è¯­è¨€ä»£ç ï¼ˆzh, en, jaç­‰ï¼‰
            prompt: å¯é€‰çš„æç¤ºè¯ï¼Œæé«˜å‡†ç¡®åº¦
            response_format: è¿”å›æ ¼å¼ï¼ˆtext, json, srt, verbose_json, vttï¼‰

        Returns:
            dict: {
                "text": "è½¬å†™æ–‡æœ¬",
                "duration": 12.5,  # æ—¶é•¿ï¼ˆç§’ï¼‰
            }
        """
        # ä¿å­˜ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
        with tempfile.NamedTemporaryFile(
            suffix=".mp3",
            delete=False
        ) as temp_file:
            temp_file.write(audio_data)
            temp_path = temp_file.name

        try:
            # è°ƒç”¨Whisper API
            with open(temp_path, "rb") as audio_file:
                transcription = self.client.audio.transcriptions.create(
                    model=self.model,
                    file=audio_file,
                    language=language,
                    prompt=prompt,
                    response_format=response_format
                )

            return {
                "text": transcription.text if hasattr(transcription, 'text') else transcription,
                "duration": self._get_audio_duration(temp_path)
            }

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(temp_path)

    def transcribe_with_timestamps(
        self,
        audio_data: bytes,
        language: str = "zh"
    ) -> dict:
        """
        è½¬å†™éŸ³é¢‘ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰

        Returns:
            dict: {
                "text": "å®Œæ•´æ–‡æœ¬",
                "words": [
                    {"word": "ä½ ", "start": 0.0, "end": 0.5},
                    {"word": "å¥½", "start": 0.5, "end": 1.0},
                ]
            }
        """
        with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as f:
            f.write(audio_data)
            temp_path = f.name

        try:
            with open(temp_path, "rb") as audio_file:
                response = self.client.audio.transcriptions.create(
                    model=self.model,
                    file=audio_file,
                    language=language,
                    timestamp_granularities=["word"],
                    response_format="verbose_json"
                )

            return {
                "text": response.text,
                "words": response.words
            }

        finally:
            os.unlink(temp_path)

    @staticmethod
    def _get_audio_duration(file_path: str) -> float:
        """è·å–éŸ³é¢‘æ—¶é•¿"""
        from pydub import AudioSegment
        audio = AudioSegment.from_mp3(file_path)
        return len(audio) / 1000.0  # è½¬æ¢ä¸ºç§’
```

### 4.3 æœ¬åœ°å¤‡ç”¨æ–¹æ¡ˆ

```python
# core/stt_local.py

from faster_whisper import WhisperModel
from typing import Optional

class LocalSpeechToText:
    """æœ¬åœ°è¯­éŸ³è½¬æ–‡å­—ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""

    def __init__(
        self,
        model_size: str = "base",
        device: str = "cpu",
        compute_type: str = "int8"
    ):
        """
        åˆå§‹åŒ–æœ¬åœ°STT

        Args:
            model_size: æ¨¡å‹å¤§å°ï¼ˆtiny, base, small, medium, large-v3ï¼‰
            device: è®¾å¤‡ï¼ˆcpu, cudaï¼‰
            compute_type: è®¡ç®—ç±»å‹ï¼ˆint8, float16, float32ï¼‰
        """
        self.model = WhisperModel(
            model_size,
            device=device,
            compute_type=compute_type
        )

    def transcribe(
        self,
        audio_path: str,
        language: str = "zh"
    ) -> dict:
        """
        è½¬å†™éŸ³é¢‘æ–‡ä»¶

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: è¯­è¨€ä»£ç 

        Returns:
            dict: è½¬å†™ç»“æœ
        """
        segments, info = self.model.transcribe(
            audio_path,
            language=language,
            word_timestamps=True
        )

        result = {
            "text": "",
            "language": info.language,
            "duration": info.duration,
            "segments": []
        }

        for segment in segments:
            result["segments"].append({
                "start": segment.start,
                "end": segment.end,
                "text": segment.text
            })
            result["text"] += segment.text

        return result
```

---

## äº”ã€æ–‡å­—è½¬è¯­éŸ³

### 5.1 é€‰æ‹©ï¼šOpenAI TTS

**é€‰æ‹©ç†ç”±ï¼š**
1. âœ… é«˜è´¨é‡è¾“å‡º
2. âœ… ä½å»¶è¿Ÿï¼ˆ1-2sï¼‰
3. âœ… ç®€å•é›†æˆ
4. âœ… ç¨³å®šå¯é 

**ç¼ºç‚¹ï¼š**
- âŒ å£°éŸ³é€‰æ‹©æœ‰é™ï¼ˆ6ç§ï¼‰
- âŒ ä¸­æ–‡å£éŸ³æ˜æ˜¾
- âŒ ä¾èµ–ç½‘ç»œ

**å¤‡ç”¨æ–¹æ¡ˆï¼š** Coqui TTSï¼ˆæœ¬åœ°ï¼‰

### 5.2 æ ¸å¿ƒä»£ç 

```python
# core/tts.py

import os
from io import BytesIO
from typing import Literal
from openai import OpenAI

class TextToSpeech:
    """æ–‡å­—è½¬è¯­éŸ³ï¼ˆTTSï¼‰"""

    # å¯ç”¨å£°éŸ³
    VOICES = ["alloy", "echo", "fissure", "onyx", "nova", "shimmer"]

    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–TTSæœåŠ¡

        Args:
            api_key: OpenAI API Key
        """
        self.client = OpenAI(api_key=api_key or os.getenv("OPENAI_API_KEY"))

    def synthesize(
        self,
        text: str,
        voice: Literal["alloy", "echo", "fissure", "onyx", "nova", "shimmer"] = "alloy",
        model: Literal["tts-1", "tts-1-hd"] = "tts-1",
        speed: float = 1.0,
        return_format: Literal["mp3", "opus", "aac", "flac"] = "mp3"
    ) -> bytes:
        """
        åˆæˆè¯­éŸ³

        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            voice: å£°éŸ³é€‰æ‹©
            model: æ¨¡å‹é€‰æ‹©ï¼ˆtts-1æ ‡å‡†, tts-1-hdé«˜è´¨é‡ï¼‰
            speed: è¯­é€Ÿï¼ˆ0.25-4.0ï¼‰
            return_format: è¿”å›æ ¼å¼

        Returns:
            bytes: éŸ³é¢‘æ•°æ®
        """
        response = self.client.audio.speech.create(
            model=model,
            voice=voice,
            input=text,
            speed=speed,
            response_format=return_format
        )

        # è¯»å–éŸ³é¢‘æ•°æ®
        audio_data = BytesIO()
        for chunk in response.iter_bytes(chunk_size=4096):
            audio_data.write(chunk)

        return audio_data.getvalue()

    def synthesize_to_file(
        self,
        text: str,
        output_path: str,
        voice: str = "alloy"
    ) -> str:
        """
        åˆæˆè¯­éŸ³å¹¶ä¿å­˜åˆ°æ–‡ä»¶

        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            voice: å£°éŸ³é€‰æ‹©

        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        response = self.client.audio.speech.create(
            model="tts-1",
            voice=voice,
            input=text
        )

        response.stream_to_file(output_path)
        return output_path

    async def synthesize_async(
        self,
        text: str,
        voice: str = "alloy"
    ) -> bytes:
        """å¼‚æ­¥åˆæˆè¯­éŸ³"""
        # å¼‚æ­¥ç‰ˆæœ¬å®ç°
        import asyncio
        return await asyncio.to_thread(self.synthesize, text, voice)
```

---

## å…­ã€AIå¯¹è¯

### 6.1 é€‰æ‹©ï¼šClaude 3.5

**é€‰æ‹©ç†ç”±ï¼š**
1. âœ… æœ€ä½³æ¨ç†èƒ½åŠ›
2. âœ… é•¿ä¸Šä¸‹æ–‡ï¼ˆ200K tokensï¼‰
3. âœ… è‡ªç„¶å¯¹è¯é£æ ¼
4. âœ… ä¼˜ç§€çš„ä¸­æ–‡æ”¯æŒ

**æ¨¡å‹é€‰æ‹©ç­–ç•¥ï¼š**
- **Haiku**ï¼ˆ$0.8/1Mï¼‰ï¼šç®€å•é—®ç­”ï¼Œå¿«é€Ÿå“åº”
- **Sonnet**ï¼ˆ$3/1Mï¼‰ï¼šå¤æ‚æ¨ç†ï¼Œé«˜è´¨é‡

### 6.2 æ ¸å¿ƒä»£ç 

```python
# core/ai_client.py

import os
from typing import Literal, Optional, List
from anthropic import Anthropic

class AIClient:
    """AIå¯¹è¯å®¢æˆ·ç«¯ï¼ˆClaudeï¼‰"""

    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–AIå®¢æˆ·ç«¯

        Args:
            api_key: Anthropic API Key
        """
        self.client = Anthropic(api_key=api_key or os.getenv("ANTHROPIC_API_KEY"))

    def chat(
        self,
        messages: List[dict],
        model: Literal["claude-3-5-haiku-20241022", "claude-3-5-sonnet-20241022"] = "claude-3-5-haiku-20241022",
        max_tokens: int = 1024,
        system_prompt: Optional[str] = None,
        temperature: float = 0.7
    ) -> str:
        """
        ä¸AIå¯¹è¯

        Args:
            messages: å¯¹è¯å†å² [{"role": "user", "content": "..."}]
            model: æ¨¡å‹é€‰æ‹©
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            temperature: æ¸©åº¦ï¼ˆ0-1ï¼Œè¶Šé«˜è¶Šéšæœºï¼‰

        Returns:
            str: AIå›å¤
        """
        kwargs = {
            "model": model,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "messages": messages
        }

        if system_prompt:
            kwargs["system"] = system_prompt

        response = self.client.messages.create(**kwargs)

        return response.content[0].text

    def chat_with_context(
        self,
        user_input: str,
        context: List[dict],
        use_haiku: bool = True
    ) -> str:
        """
        å¸¦ä¸Šä¸‹æ–‡çš„å¯¹è¯

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            context: ä¸Šä¸‹æ–‡å†å²
            use_haiku: æ˜¯å¦ä½¿ç”¨Haikuï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰

        Returns:
            str: AIå›å¤
        """
        # æ„å»ºæ¶ˆæ¯å†å²
        messages = context + [{"role": "user", "content": user_input}]

        # æ ¹æ®è¾“å…¥å¤æ‚åº¦é€‰æ‹©æ¨¡å‹
        if use_haiku and len(user_input) < 200:
            model = "claude-3-5-haiku-20241022"
        else:
            model = "claude-3-5-sonnet-20241022"

        return self.chat(messages, model=model)

    def stream_chat(
        self,
        messages: List[dict],
        model: str = "claude-3-5-sonnet-20241022"
    ):
        """æµå¼å¯¹è¯ï¼ˆå®æ—¶ç”Ÿæˆï¼‰"""
        with self.client.messages.stream(
            model=model,
            max_tokens=1024,
            messages=messages
        ) as stream:
            for text in stream.text_stream:
                yield text
```

### 6.3 å¯¹è¯ç®¡ç†å™¨

```python
# core/conversation.py

from typing import List, Dict
from core.ai_client import AIClient

class ConversationManager:
    """å¯¹è¯ç®¡ç†å™¨"""

    def __init__(
        self,
        system_prompt: str = "ä½ æ˜¯Voice Memoryï¼Œä¸€ä¸ªæœ‰è®°å¿†çš„AIåŠ©æ‰‹ã€‚",
        max_history: int = 20
    ):
        """
        åˆå§‹åŒ–å¯¹è¯ç®¡ç†å™¨

        Args:
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            max_history: æœ€å¤§å†å²è®°å½•æ•°
        """
        self.ai_client = AIClient()
        self.system_prompt = system_prompt
        self.max_history = max_history
        self.history: List[Dict] = []

    def add_user_message(self, content: str):
        """æ·»åŠ ç”¨æˆ·æ¶ˆæ¯"""
        self.history.append({"role": "user", "content": content})

    def add_assistant_message(self, content: str):
        """æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯"""
        self.history.append({"role": "assistant", "content": content})

    def get_response(self, user_input: str) -> str:
        """è·å–AIå›å¤"""
        # æ·»åŠ ç”¨æˆ·è¾“å…¥
        self.add_user_message(user_input)

        # è°ƒç”¨AI
        response = self.ai_client.chat(
            messages=self.history,
            system_prompt=self.system_prompt
        )

        # æ·»åŠ åŠ©æ‰‹å›å¤
        self.add_assistant_message(response)

        # ä¿æŒå†å²åœ¨åˆç†å¤§å°
        if len(self.history) > self.max_history:
            self.history = self.history[-self.max_history:]

        return response

    def clear_history(self):
        """æ¸…ç©ºå†å²"""
        self.history = []

    def load_context(self, context: List[Dict]):
        """åŠ è½½ä¸Šä¸‹æ–‡"""
        self.history = context.copy()
```

---

## ä¸ƒã€è®°å¿†å­˜å‚¨

### 7.1 é€‰æ‹©ï¼šMarkdown + SQLite

**é€‰æ‹©ç†ç”±ï¼š**
1. âœ… äººç±»å¯è¯»
2. âœ… ç‰ˆæœ¬æ§åˆ¶å‹å¥½
3. âœ… æ˜“äºè¿ç§»
4. âœ… Obsidianå…¼å®¹

### 7.2 æ ¸å¿ƒä»£ç 

```python
# core/memory.py

import os
import sqlite3
from pathlib import Path
from datetime import datetime
from typing import List, Optional, Dict
import frontmatter

class MemoryStore:
    """è®°å¿†å­˜å‚¨ç³»ç»Ÿ"""

    def __init__(self, base_path: str = "~/basic-memory"):
        """
        åˆå§‹åŒ–è®°å¿†å­˜å‚¨

        Args:
            base_path: åŸºç¡€è·¯å¾„
        """
        self.base_path = Path(base_path).expanduser()
        self.base_path.mkdir(parents=True, exist_ok=True)

        self.db_path = self.base_path / "memory.db"
        self._init_db()

    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        self.conn = sqlite3.connect(self.db_path)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS entities (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                permalink TEXT UNIQUE,
                type TEXT DEFAULT 'note',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS observations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                entity_id INTEGER,
                category TEXT,
                content TEXT NOT NULL,
                tags TEXT,
                context TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (entity_id) REFERENCES entities(id)
            )
        """)

        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS relations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source_entity_id INTEGER,
                target_entity_id INTEGER,
                relation_type TEXT,
                context TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (source_entity_id) REFERENCES entities(id),
                FOREIGN KEY (target_entity_id) REFERENCES entities(id)
            )
        """)

        self.conn.commit()

    def save_note(
        self,
        title: str,
        content: str,
        tags: Optional[List[str]] = None,
        relations: Optional[List[Dict]] = None
    ) -> str:
        """
        ä¿å­˜ç¬”è®°

        Args:
            title: æ ‡é¢˜
            content: å†…å®¹
            tags: æ ‡ç­¾åˆ—è¡¨
            relations: å…³ç³»åˆ—è¡¨ [{"target": "xxx", "type": "relates_to"}]

        Returns:
            str: permalink
        """
        permalink = self._generate_permalink(title)
        date_str = datetime.now().strftime("%Y-%m-%d")

        # åˆ›å»ºMarkdownæ–‡ä»¶
        post = frontmatter.Post(content)
        post['title'] = title
        post['permalink'] = permalink
        post['tags'] = tags or []
        post['created'] = date_str

        # ä¿å­˜æ–‡ä»¶
        file_dir = self.base_path / date_str
        file_dir.mkdir(parents=True, exist_ok=True)
        file_path = file_dir / f"{permalink}.md"

        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(frontmatter.dumps(post))

        # ä¿å­˜åˆ°æ•°æ®åº“
        cursor = self.conn.execute(
            "INSERT INTO entities (title, permalink) VALUES (?, ?)",
            (title, permalink)
        )
        entity_id = cursor.lastrowid

        # ä¿å­˜æ ‡ç­¾
        if tags:
            for tag in tags:
                self.conn.execute(
                    "INSERT INTO observations (entity_id, category, content, tags) VALUES (?, ?, ?, ?)",
                    (entity_id, 'tag', '', tag)
                )

        # ä¿å­˜å…³ç³»
        if relations:
            for rel in relations:
                self.conn.execute(
                    """INSERT INTO relations (source_entity_id, target_entity_id, relation_type, context)
                       VALUES (?, ?, ?, ?)""",
                    (entity_id, rel['target'], rel['type'], rel.get('context', ''))
                )

        self.conn.commit()

        return permalink

    def search(self, query: str) -> List[Dict]:
        """æœç´¢ç¬”è®°"""
        cursor = self.conn.execute(
            """SELECT id, title, permalink, created_at
               FROM entities
               WHERE title LIKE ? OR type LIKE ?""",
            (f"%{query}%", f"%{query}%")
        )

        return [dict(row) for row in cursor.fetchall()]

    def get_note(self, permalink: str) -> Optional[Dict]:
        """è·å–ç¬”è®°å†…å®¹"""
        # æŸ¥æ‰¾æ–‡ä»¶
        for md_file in self.base_path.rglob("*.md"):
            if md_file.stem == permalink:
                with open(md_file, 'r', encoding='utf-8') as f:
                    post = frontmatter.load(f)
                    return {
                        'title': post.get('title'),
                        'content': post.content,
                        'metadata': post.metadata
                    }
        return None

    def _generate_permalink(self, title: str) -> str:
        """ç”Ÿæˆpermalink"""
        import re
        # è½¬å°å†™ï¼Œæ›¿æ¢ç©ºæ ¼ä¸ºè¿å­—ç¬¦
        permalink = re.sub(r'\s+', '-', title.lower())
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
        permalink = re.sub(r'[^\w\-]', '', permalink)
        return permalink

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        self.conn.close()
```

---

## å…«ã€å®Œæ•´ç¤ºä¾‹

### 8.1 ç«¯åˆ°ç«¯å¯¹è¯ç¤ºä¾‹

```python
#!/usr/bin/env python3
"""
Voice Memory - å®Œæ•´å¯¹è¯ç¤ºä¾‹
"""

import os
import asyncio
from core.wake_word import WakeWordDetector
from core.stt import SpeechToText
from core.tts import TextToSpeech
from core.conversation import ConversationManager
from core.memory import MemoryStore

class VoiceMemory:
    """Voice Memoryä¸»ç±»"""

    def __init__(self):
        """åˆå§‹åŒ–"""
        # åˆå§‹åŒ–ç»„ä»¶
        self.wake_word = WakeWordDetector(
            access_key=os.getenv("PICOVOICE_ACCESS_KEY"),
            keyword_path="wake_words/memory.ppn"
        )

        self.stt = SpeechToText()
        self.tts = TextToSpeech()
        self.conversation = ConversationManager()
        self.memory = MemoryStore()

        # çŠ¶æ€
        self.is_listening = False

    def on_wake_word_detected(self):
        """æ£€æµ‹åˆ°å”¤é†’è¯"""
        print("ğŸ¤ æ£€æµ‹åˆ°å”¤é†’è¯ï¼")
        self.is_listening = True

    async def listen_and_respond(self):
        """ç›‘å¬å¹¶å“åº”"""
        if not self.is_listening:
            return

        print("ğŸ§ æ­£åœ¨è†å¬...")

        # 1. å½•éŸ³ï¼ˆ5ç§’ï¼‰
        audio_data = await self.record_audio(duration=5)

        # 2. STT
        print("ğŸ“ è½¬å†™ä¸­...")
        result = self.stt.transcribe(audio_data)
        user_text = result['text']
        print(f"ğŸ‘¤ ç”¨æˆ·: {user_text}")

        # 3. AIå¯¹è¯
        print("ğŸ¤– æ€è€ƒä¸­...")
        response = self.conversation.get_response(user_text)
        print(f"ğŸ¤– AI: {response}")

        # 4. TTS
        print("ğŸ”Š åˆæˆè¯­éŸ³...")
        audio_output = self.tts.synthesize(response)
        await self.play_audio(audio_output)

        # 5. åˆ¤æ–­æ˜¯å¦å½’æ¡£
        if self.should_archive(user_text, response):
            print("ğŸ’¾ å½’æ¡£ä¸­...")
            self.memory.save_note(
                title=user_text[:50],
                content=f"## ç”¨æˆ·\n{user_text}\n\n## AI\n{response}"
            )

        self.is_listening = False

    async def record_audio(self, duration: int = 5) -> bytes:
        """å½•éŸ³"""
        import pyaudio
        import wave

        chunk = 1024
        sample_format = pyaudio.paInt16
        channels = 1
        fs = 44100
        seconds = duration

        p = pyaudio.PyAudio()
        stream = p.open(format=sample_format,
                       channels=channels,
                       rate=fs,
                       frames_per_buffer=chunk,
                       input=True)

        frames = []
        for _ in range(int(fs / chunk * seconds)):
            data = stream.read(chunk)
            frames.append(data)

        stream.stop_stream()
        stream.close()
        p.terminate()

        # è½¬æ¢ä¸ºbytes
        return b''.join(frames)

    async def play_audio(self, audio_data: bytes):
        """æ’­æ”¾éŸ³é¢‘"""
        import pyaudio

        p = pyaudio.PyAudio()
        stream = p.open(format=pyaudio.paInt16,
                       channels=1,
                       rate=24000,
                       output=True)

        stream.write(audio_data)
        stream.stop_stream()
        stream.close()
        p.terminate()

    def should_archive(self, user_input: str, response: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å½’æ¡£"""
        # ç®€å•è§„åˆ™ï¼šè¶…è¿‡20å­—çš„å¯¹è¯
        return len(user_input) + len(response) > 20

    async def run(self):
        """è¿è¡Œä¸»å¾ªç¯"""
        print("ğŸš€ Voice Memory å¯åŠ¨...")
        print("ğŸ“¢ è¯´'Memory'å”¤é†’æˆ‘")

        # å¯åŠ¨å”¤é†’è¯ç›‘å¬
        self.wake_word.start()
        self.wake_word.on_detected = self.on_wake_word_detected

        # å¼‚æ­¥ç›‘å¬å”¤é†’è¯
        import threading
        wake_thread = threading.Thread(target=self.wake_word.listen)
        wake_thread.daemon = True
        wake_thread.start()

        # ä¸»å¾ªç¯
        while True:
            if self.is_listening:
                await self.listen_and_respond()
            await asyncio.sleep(0.1)

if __name__ == "__main__":
    vm = VoiceMemory()
    asyncio.run(vm.run())
```

### 8.2 Terminal CLIç¤ºä¾‹

```python
#!/usr/bin/env python3
"""
Voice Memory - Terminal CLI
"""

import typer
from rich.console import Console
from rich.table import Table

app = typer.Typer()
console = Console()

@app.command()
def chat(message: str):
    """ä¸AIå¯¹è¯"""
    from core.conversation import ConversationManager

    cm = ConversationManager()
    response = cm.get_response(message)

    console.print(f"[bold blue]AI:[/bold blue] {response}")

@app.command()
def save(title: str, content: str):
    """ä¿å­˜ç¬”è®°"""
    from core.memory import MemoryStore

    memory = MemoryStore()
    permalink = memory.save_note(title=title, content=content)

    console.print(f"âœ… å·²ä¿å­˜: {permalink}")

@app.command()
def search(query: str):
    """æœç´¢ç¬”è®°"""
    from core.memory import MemoryStore

    memory = MemoryStore()
    results = memory.search(query)

    table = Table(title="æœç´¢ç»“æœ")
    table.add_column("æ ‡é¢˜", style="cyan")
    table.add_column("é“¾æ¥", style="green")
    table.add_column("æ—¶é—´", style="yellow")

    for result in results:
        table.add_row(result['title'], result['permalink'], result['created_at'])

    console.print(table)

@app.command()
def listen():
    """è¯­éŸ³å¯¹è¯"""
    import asyncio
    from complete_example import VoiceMemory

    async def _listen():
        vm = VoiceMemory()
        await vm.run()

    asyncio.run(_listen())

if __name__ == "__main__":
    app()
```

---

## ä¹ã€ç¯å¢ƒé…ç½®

### 9.1 ç¯å¢ƒå˜é‡

```bash
# .env

# Picovoice
PICOVOICE_ACCESS_KEY=your_access_key_here

# OpenAI
OPENAI_API_KEY=sk-your-openai-key-here

# Anthropic
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Memory Storage
MEMORY_BASE_PATH=~/basic-memory
```

### 9.2 å¿«é€Ÿå¼€å§‹

```bash
# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 3. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘.envï¼Œå¡«å…¥API Keys

# 4. è¿è¡Œ
python -m complete_example
```

---

## åã€æ•…éšœæ’æŸ¥

### 10.1 å¸¸è§é—®é¢˜

| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| å”¤é†’è¯æ— å“åº” | éº¦å…‹é£æƒé™ | æ£€æŸ¥ç³»ç»Ÿéº¦å…‹é£æƒé™ |
| STTå¤±è´¥ | API Keyé”™è¯¯ | éªŒè¯OPENAI_API_KEY |
| TTSæ— å£°éŸ³ | æ’­æ”¾è®¾å¤‡é”™è¯¯ | æ£€æŸ¥ç³»ç»ŸéŸ³é¢‘è¾“å‡º |
| æ•°æ®åº“é”™è¯¯ | æ–‡ä»¶æƒé™ | æ£€æŸ¥MEMORY_BASE_PATHæƒé™ |

### 10.2 è°ƒè¯•æ¨¡å¼

```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
export DEBUG=1
python -m complete_example
```

---

**æ–‡æ¡£ç‰ˆæœ¬å†å²ï¼š**
- v0.1 (2025-12-29): åˆå§‹ç‰ˆæœ¬
