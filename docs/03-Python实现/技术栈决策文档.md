# Voice Memory - 技术栈决策文档

**版本：** v0.1
**日期：** 2025-12-29
**状态：** 最终决策版本

---

## 目录

1. [决策框架](#一决策框架)
2. [后端技术栈](#二后端技术栈)
3. [前端技术栈](#三前端技术栈)
4. [AI服务栈](#四ai服务栈)
5. [音频技术栈](#五音频技术栈)
6. [存储技术栈](#六存储技术栈)
7. [DevOps技术栈](#七devops技术栈)
8. [最终决策总结](#八最终决策总结)

---

## 一、决策框架

### 1.1 决策原则

| 原则 | 权重 | 说明 |
|------|------|------|
| **快速验证** | ⭐⭐⭐⭐⭐ | MVP优先，快速迭代 |
| **成本可控** | ⭐⭐⭐⭐ | 早期控制API成本 |
| **可扩展性** | ⭐⭐⭐⭐ | 为Phase 2/3预留空间 |
| **开发效率** | ⭐⭐⭐⭐ | 选择熟悉、文档丰富的技术 |
| **社区支持** | ⭐⭐⭐ | 优先选择活跃社区 |

### 1.2 决策矩阵

```
评分标准（每个技术）：
  ✅ 成熟度: 1-5分
  ✅ 文档质量: 1-5分
  ✅ 社区活跃度: 1-5分
  ✅ 学习曲线: 1-5分（5=容易学）
  ✅ 成本: 1-5分（5=低成本）
  ✅ 性能: 1-5分
  ───────────────────────
  总分: 30分（满分）

决策标准：
  - 总分 ≥25分: 优先选择
  - 总分 20-24分: 可以考虑，需权衡
  - 总分 <20分: 不推荐
```

---

## 二、后端技术栈

### 2.1 编程语言

| 语言 | 成熟度 | 文档 | 社区 | 学习 | 成本 | 性能 | 总分 | 决策 |
|------|--------|------|------|------|------|------|------|------|
| **Python** | 5 | 5 | 5 | 5 | 5 | 3 | 28 | ✅ **选择** |
| TypeScript | 5 | 5 | 5 | 4 | 5 | 4 | 28 | ✅ 备用 |
| Go | 5 | 4 | 4 | 3 | 5 | 5 | 26 | ✅ 备用 |
| Rust | 4 | 4 | 4 | 2 | 5 | 5 | 24 | ⚠️ 考虑 |

#### 最终选择：Python

**选择理由：**
```yaml
优点:
  ✅ AI/ML生态最佳（大量现成库）
  ✅ 开发效率极高（代码简洁）
  ✅ 团队熟悉度高
  ✅ FastAPI现代化框架
  ✅ 异步支持（asyncio）
  ✅ 类型提示（typing）

缺点:
  ❌ 性能不如编译型语言
  ❌ GIL限制（但音频I/O为主，影响小）
  ❌ 打包分发稍复杂

为什么不用其他:
  TypeScript: 前端用，后端没必要全栈统一
  Go: 性能优势在MVP阶段不明显
  Rust: 学习曲线陡峭，开发速度慢
```

**备用方案：**
- 性能瓶颈时：关键模块用Rust重写
- 团队有Go经验：可考虑Go

---

### 2.2 Web框架

| 框架 | 成熟度 | 文档 | 社区 | 学习 | 成本 | 性能 | 总分 | 决策 |
|------|--------|------|------|------|------|------|------|------|
| **FastAPI** | 5 | 5 | 5 | 5 | 5 | 5 | 30 | ✅ **选择** |
| Flask | 5 | 5 | 5 | 5 | 5 | 3 | 28 | ✅ 备用 |
| Django | 5 | 5 | 5 | 3 | 5 | 3 | 23 | ⚠️ 过重 |
| Tornado | 4 | 3 | 3 | 4 | 5 | 4 | 23 | ⚠️ 过时 |

#### 最终选择：FastAPI

**选择理由：**
```yaml
优点:
  ✅ 现代化设计（异步原生）
  ✅ 自动API文档（OpenAPI/Swagger）
  ✅ 类型提示优先（Pydantic）
  ✅ WebSocket支持（Phase 2/3需要）
  ✅ 性能优秀（与Starlette相当）
  ✅ 依赖注入（测试友好）
  ✅ CORS、中间件开箱即用

缺点:
  ❌ 相对较新（但已足够成熟）
  ❌ 生态不如Flask/Django（但够用）

关键特性（对可打断重要）:
  ✅ WebSocket原生支持
  ✅ 后台任务支持
  ✅ 流式响应支持
```

**代码示例：**
```python
from fastapi import FastAPI, WebSocket
from fastapi.responses import StreamingResponse

app = FastAPI()

# REST API
@app.post("/chat")
async def chat(message: str):
    return {"response": ai_client.chat(message)}

# WebSocket（Phase 2可打断）
@app.websocket("/ws/chat")
async def chat_ws(websocket: WebSocket):
    await websocket.accept()
    while True:
        # 接收音频
        audio_data = await websocket.receive_bytes()

        # STT
        text = await stt.transcribe(audio_data)

        # AI（流式）
        async for chunk in ai_client.stream_chat(text):
            # TTS（流式）
            audio = await tts.synthesize(chunk)
            await websocket.send_bytes(audio)
```

---

### 2.3 异步任务

| 方案 | 成熟度 | 文档 | 社区 | 学习 | 成本 | 性能 | 总分 | 决策 |
|------|--------|------|------|------|------|------|------|------|
| **asyncio** | 5 | 5 | 5 | 4 | 5 | 5 | 29 | ✅ **选择** |
| Celery | 5 | 5 | 5 | 3 | 4 | 4 | 26 | ✅ 备用 |
| RQ | 4 | 4 | 4 | 5 | 5 | 3 | 25 | ✅ 备用 |

#### 最终选择：asyncio（原生）

**选择理由：**
```yaml
优点:
  ✅ Python 3.7+内置
  ✅ 零额外依赖
  ✅ 与FastAPI完美集成
  ✅ 性能足够（I/O密集型）

缺点:
  ❌ 不支持分布式（MVP不需要）
  ❌ 调试相对复杂

使用场景:
  - STT/TTS并发调用
  - WebSocket长连接
  - 流式数据处理
```

**备用方案（需要队列时）：** RQ（简单）或 Celery（复杂）

---

## 三、前端技术栈

### 3.1 macOS App

| 技术 | 成熟度 | 文档 | 社区 | 学习 | 成本 | 性能 | 总分 | 决策 |
|------|--------|------|------|------|------|------|------|------|
| **Swift + SwiftUI** | 5 | 5 | 5 | 4 | 5 | 5 | 29 | ✅ **选择** |
| Electron | 5 | 5 | 5 | 5 | 4 | 3 | 27 | ⚠️ 通用 |
| Python GUI | 3 | 3 | 3 | 5 | 5 | 3 | 22 | ❌ 不推荐 |

#### 最终选择：Swift + SwiftUI

**选择理由：**
```yaml
优点:
  ✅ 原生性能
  ✅ 系统集成深（麦克风权限、通知等）
  ✅ SwiftUI现代化（声明式UI）
  ✅ macOS 14+新特性支持
  ✅ App Store分发
  ✅ 用户体验最佳

缺点:
  ❌ 仅限macOS/iOS
  ❌ 需要Swift开发技能

关键模块:
  - AVFoundation：音频录制/播放
  - Speech Framework：备用STT
  - CallKit：系统集成
  - Notification：通知提醒
```

**项目结构：**
```
VoiceMemory/
├── VoiceMemoryApp.swift      # App入口
├── Views/
│   ├── MainView.swift         # 主界面
│   ├── ChatView.swift         # 对话界面
│   └── SettingsView.swift     # 设置
├── ViewModels/
│   └── ConversationViewModel.swift
├── Services/
│   ├── AudioService.swift     # 音频服务
│   ├── NetworkService.swift   # 网络服务
│   └── StorageService.swift   # 本地存储
└── Resources/
    ├── Assets.xcassets       # 图片资源
    └── Info.plist
```

---

### 3.2 Terminal CLI

| 技术 | 成熟度 | 文档 | 社区 | 学习 | 成本 | 性能 | 总分 | 决策 |
|------|--------|------|------|------|------|------|------|------|
| **Typer** | 5 | 5 | 5 | 5 | 5 | 5 | 30 | ✅ **选择** |
| Click | 5 | 5 | 5 | 4 | 5 | 5 | 29 | ✅ 备用 |
| argparse | 5 | 5 | 5 | 5 | 5 | 5 | 29 | ⚠️ 原生 |

#### 最终选择：Typer

**选择理由：**
```yaml
优点:
  ✅ 现代化CLI框架
  ✅ 自动帮助生成
  ✅ 类型提示支持
  ✅ Rich集成（美化输出）
  ✅ 与FastAPI同作者

缺点:
  ❌ 相对较新（但足够成熟）
```

**代码示例：**
```python
import typer
from rich.console import Console
from rich.table import Table

app = typer.Typer()
console = Console()

@app.command()
def chat(message: str):
    """与AI对话"""
    # 调用后端API
    response = backend.chat(message)
    console.print(f"[blue]AI:[/blue] {response}")

@app.command()
def save(title: str, content: str):
    """保存笔记"""
    backend.memory.save(title, content)
    console.print("✅ 已保存")

@app.command()
def listen():
    """语音对话模式"""
    console.print("🎤 语音对话模式启动...")
    # 进入语音循环
```

---

## 四、AI服务栈

### 4.1 LLM提供商

| 提供商 | 模型 | 成熟度 | 质量 | 成本 | 上下文 | 中文 | 总分 | 决策 |
|--------|------|--------|------|------|--------|------|------|------|
| **Anthropic** | Claude 3.5 | 5 | 5 | 4 | 200K | 5 | 28 | ✅ **主选** |
| **OpenAI** | GPT-4o | 5 | 5 | 4 | 128K | 5 | 28 | ✅ **备用** |
| **OpenAI** | GPT-4o-mini | 5 | 4 | 5 | 128K | 4 | 27 | ✅ **简单任务** |

#### 最终选择：Claude 3.5（Haiku + Sonnet混合）

**选择理由：**
```yaml
Claude 3.5 Haiku:
  ✅ 快速（~50 tokens/秒的3倍）
  ✅ 便宜（$0.8/1M输入）
  ✅ 200K上下文
  ✅ 适合简单任务

Claude 3.5 Sonnet:
  ✅ 最佳推理能力
  ✅ 长上下文（200K）
  ✅ 优秀中文支持
  ✅ 适合复杂任务

混合策略:
  - 简单问答 → Haiku
  - 复杂推理 → Sonnet
  - 成本节省：~40%
```

**API调用示例：**
```python
from anthropic import Anthropic

class AIClient:
    def __init__(self, api_key: str):
        self.client = Anthropic(api_key=api_key)
        self.model_haiku = "claude-3-5-haiku-20241022"
        self.model_sonnet = "claude-3-5-sonnet-20241022"

    def chat(
        self,
        messages: list,
        complexity: str = "auto"
    ) -> str:
        # 自动选择模型
        if complexity == "auto":
            text = messages[-1]["content"]
            model = self.model_haiku if len(text) < 200 else self.model_sonnet
        else:
            model = self.model_haiku if complexity == "simple" else self.model_sonnet

        response = self.client.messages.create(
            model=model,
            max_tokens=1024,
            messages=messages
        )

        return response.content[0].text
```

**成本估算（月度，1000用户）：**
```
假设：50次对话/天，50% Haiku + 50% Sonnet

Haiku: 25次 x 1000 tokens x $0.8/1M = $0.02/用户/天
Sonnet: 25次 x 1000 tokens x $3/1M = $0.075/用户/天
总计: $0.095/用户/天 = $2.85/用户/月

1000用户: $2,850/月

优化（智能路由）:
  简单任务70% → $0.065/用户/天 = $1,950/月
```

---

## 五、音频技术栈

### 5.1 STT（语音转文字）

| 方案 | 准确度 | 延迟 | 隐私 | 成本 | 语言 | 总分 | 决策 |
|------|--------|------|------|------|------|------|------|
| **Whisper API** | 5 | 3 | 3 | 4 | 5 | 25 | ✅ **主选** |
| **Whisper本地** | 4 | 2 | 5 | 5 | 5 | 26 | ✅ **备用** |
| Azure Speech | 5 | 4 | 3 | 3 | 5 | 24 | ⚠️ 考虑 |

#### 最终选择：OpenAI Whisper API（主）+ Whisper本地（备用）

**选择理由：**
```yaml
Whisper API:
  ✅ 准确度最高（7.6% WER）
  ✅ 简单集成
  ✅ 99语言支持
  ✅ 持续更新

Whisper本地（faster-whisper）:
  ✅ 完全隐私
  ✅ 无API成本
  ✅ 可离线使用
  ✅ 与API模型质量接近

混合策略:
  - 默认: Whisper API（快速验证）
  - 隐私模式: Whisper本地（可选）
  - 成本优化: 本地处理 >30秒音频
```

**代码架构：**
```python
from abc import ABC, abstractmethod

class STTProvider(ABC):
    @abstractmethod
    async def transcribe(self, audio: bytes) -> str:
        pass

class WhisperAPI(STTProvider):
    """Whisper API实现"""
    async def transcribe(self, audio: bytes) -> str:
        # 调用OpenAI API
        pass

class WhisperLocal(STTProvider):
    """Whisper本地实现"""
    def __init__(self, model_size="base"):
        from faster_whisper import WhisperModel
        self.model = WhisperModel(model_size, device="cpu", compute_type="int8")

    async def transcribe(self, audio: bytes) -> str:
        # 本地推理
        pass

class STTRouter:
    """STT路由器"""
    def __init__(self, mode="api"):
        self.mode = mode
        self.api = WhisperAPI()
        self.local = WhisperLocal()

    async def transcribe(self, audio: bytes, prefer_local: bool = False) -> str:
        if prefer_local or self.mode == "local":
            return await self.local.transcribe(audio)
        return await self.api.transcribe(audio)
```

---

### 5.2 TTS（文字转语音）

| 方案 | 质量 | 延迟 | 隐私 | 成本 | 声音 | 总分 | 决策 |
|------|------|------|------|------|------|------|------|
| **OpenAI TTS** | 4 | 3 | 3 | 4 | 6 | 24 | ✅ **主选** |
| **ElevenLabs** | 5 | 3 | 3 | 2 | 100+ | 26 | ✅ **高质量** |
| **Coqui TTS** | 3 | 2 | 5 | 5 | 1000+ | 25 | ✅ **本地备用** |

#### 最终选择：OpenAI TTS

**选择理由：**
```yaml
优点:
  ✅ 与STT同生态（OpenAI）
  ✅ 简单集成
  ✅ 流式支持（Phase 2需要）
  ✅ 6种高质量声音
  ✅ 中英文都不错

缺点:
  ❌ 声音选择相对少
  ❌ 中文有口音

备用方案:
  - 高质量需求: ElevenLabs
  - 完全本地: Coqui TTS
```

**流式TTS实现（Phase 2准备）：**
```python
class TTSProvider:
    async def synthesize_stream(self, text: str):
        """流式合成（分块返回）"""
        # 按句子分割
        sentences = self._split_sentences(text)

        for sentence in sentences:
            # 生成音频块
            audio_chunk = await self._synthesize_single(sentence)
            yield audio_chunk

# 使用
async for chunk in tts.synthesize_stream(long_text):
    await play_audio(chunk)  # 边生成边播放
```

---

### 5.3 唤醒词检测

| 方案 | 准确度 | 延迟 | 隐私 | 成本 | 自定义 | 总分 | 决策 |
|------|--------|------|------|------|--------|------|------|
| **Porcupine** | 5 | 5 | 5 | 2 | 5 | 27 | ✅ **MVP** |
| **openWakeWord** | 4 | 4 | 5 | 5 | 5 | 28 | ✅ **长期** |
| **Vocal Shortcuts** | 3 | 5 | 5 | 5 | 2 | 25 | ⚠️ iOS |

#### 最终选择：Porcupine（MVP）→ openWakeWord（长期）

**选择理由：**
```yaml
Porcupine（MVP阶段）:
  ✅ 快速验证
  ✅ 免费版可用（个人非商业）
  ✅ 准确度最高（91%+）
  ✅ 自定义唤醒词

openWakeWord（长期）:
  ✅ 完全开源免费
  ✅ 商业友好
  ✅ 可自训练
  ✅ 社区活跃

迁移时机:
  - 用户量 > 1000
  - 或商业授权成本 > $500/月
  - 或需要深度定制
```

---

## 六、存储技术栈

### 6.1 核心存储

| 方案 | 结构化 | 可读性 | 查询 | 成本 | 复杂度 | 总分 | 决策 |
|------|--------|--------|------|------|--------|------|------|
| **Markdown + SQLite** | 4 | 5 | 4 | 5 | 2 | 25 | ✅ **选择** |
| 纯向量DB | 3 | 1 | 5 | 4 | 4 | 21 | ❌ 不推荐 |
| PostgreSQL | 5 | 2 | 5 | 4 | 4 | 24 | ⚠️ 过重 |

#### 最终选择：Markdown + SQLite（参考Basic Memory）

**选择理由：**
```yaml
Markdown文件:
  ✅ 人类可直接编辑
  ✅ Git版本控制
  ✅ Obsidian兼容
  ✅ 易于迁移备份

SQLite:
  ✅ 零配置
  ✅ 轻量级
  ✅ ACID支持
  ✅ Python内置

向量数据库（Phase 2+）:
  ✅ Chroma: 轻量，本地优先
  ✅ Qdrant: 高性能，生产级
```

**数据模型：**
```sql
-- 实体（每个笔记）
CREATE TABLE entities (
    id INTEGER PRIMARY KEY,
    title TEXT NOT NULL,
    permalink TEXT UNIQUE,
    type TEXT DEFAULT 'note',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 观察记录（笔记要点）
CREATE TABLE observations (
    id INTEGER PRIMARY KEY,
    entity_id INTEGER REFERENCES entities(id),
    category TEXT,
    content TEXT NOT NULL,
    tags TEXT,
    context TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 关系（知识图谱）
CREATE TABLE relations (
    id INTEGER PRIMARY KEY,
    source_entity_id INTEGER REFERENCES entities(id),
    target_entity_id INTEGER REFERENCES entities(id),
    relation_type TEXT,
    context TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

---

## 七、DevOps技术栈

### 7.1 容器化

| 方案 | 成熟度 | 文档 | 社区 | 学习 | 成本 | 总分 | 决策 |
|------|--------|------|------|------|------|------|------|
| **Docker** | 5 | 5 | 5 | 4 | 5 | 29 | ✅ **选择** |
| Podman | 4 | 4 | 4 | 4 | 5 | 25 | ⚠️ 备用 |

#### 最终选择：Docker

**选择理由：**
```yaml
优点:
  ✅ 行业标准
  ✅ 跨平台
  ✅ 生态完善
  ✅ 部署简单

Dockerfile示例:
FROM python:3.12-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

### 7.2 进程管理

| 方案 | 成熟度 | 文档 | 社区 | 学习 | 总分 | 决策 |
|------|--------|------|------|------|------|------|
| **systemd** | 5 | 5 | 5 | 4 | 29 | ✅ **Linux** |
| **launchd** | 5 | 4 | 5 | 3 | 27 | ✅ **macOS** |
| **Docker Compose** | 5 | 5 | 5 | 5 | 30 | ✅ **跨平台** |

#### 最终选择：Docker Compose

**docker-compose.yml：**
```yaml
version: '3.8'

services:
  api:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    volumes:
      - ./storage:/app/storage
    restart: unless-stopped
```

---

## 八、最终决策总结

### 8.1 技术栈总览

```
┌─────────────────────────────────────────────────────────────────┐
│                   Voice Memory 技术栈                             │
└─────────────────────────────────────────────────────────────────┘

后端:
  ├─ 语言: Python 3.12+
  ├─ 框架: FastAPI 0.100+
  ├─ 异步: asyncio (原生)
  └─ CLI: Typer (开发工具)

前端:
  ├─ macOS: Swift + SwiftUI
  ├─ CLI: Typer + Rich
  └─ 跨平台: 暂不考虑

AI服务:
  ├─ LLM: Claude 3.5 (Haiku + Sonnet混合)
  ├─ STT: OpenAI Whisper API
  ├─ TTS: OpenAI TTS
  └─ 唤醒词: Porcupine (MVP) → openWakeWord (长期)

存储:
  ├─ 文件: Markdown (人类可读)
  ├─ 数据库: SQLite (索引)
  └─ 向量: Chroma (Phase 2+)

DevOps:
  ├─ 容器: Docker
  ├─ 编排: Docker Compose (MVP) → K8s (生产)
  └─ CI/D: GitHub Actions
```

### 8.2 依赖清单

```txt
# requirements.txt

# Web框架
fastapi==0.100.0
uvicorn[standard]==0.23.0
websockets==12.0

# AI服务
anthropic==0.18.0
openai==1.3.0

# 语音处理
pvporcupine==3.0.0
pyaudio==0.2.13
faster-whisper==1.0.0
webrtcvad==2.0.10

# 存储
sqlalchemy==2.0.0
chromadb==0.4.0

# 工具
python-dotenv==1.0.0
typer==0.9.0
rich==13.0.0
pydantic==2.0.0

# 开发工具
pytest==7.4.0
black==23.12.0
ruff==0.1.0
```

### 8.3 项目结构

```
voice-memory/
├── backend/
│   ├── api/
│   │   ├── __init__.py
│   │   ├── main.py              # FastAPI入口
│   │   ├── routes/              # API路由
│   │   └── schemas/             # Pydantic模型
│   │
│   ├── core/                   # 核心业务逻辑
│   │   ├── stt.py               # STT服务
│   │   ├── tts.py               # TTS服务
│   │   ├── ai_client.py         # AI客户端
│   │   ├── memory.py            # 记忆存储
│   │   └── conversation.py      # 对话管理
│   │
│   ├── models/                 # 数据模型
│   │   ├── database.py          # SQLAlchemy模型
│   │   └── schemas.py          # API Schema
│   │
│   ├── config/                 # 配置
│   │   ├── settings.py          # 应用配置
│   │   └── logging.py           # 日志配置
│   │
│   └── utils/                  # 工具函数
│       ├── audio.py             # 音频工具
│       └── cache.py            # 缓存工具
│
├── clients/
│   ├── macos/
│   │   └── VoiceMemory/
│   │       ├── App/
│   │       ├── Models/
│   │       ├── Views/
│   │       └── Services/
│   │
│   └── terminal/
│       └── vm.py               # CLI入口
│
├── storage/
│   ├── markdown/                # Markdown文件
│   └── memory.db               # SQLite数据库
│
├── tests/
│   ├── unit/
│   ├── integration/
│   └── e2e/
│
├── scripts/
│   ├── setup.sh                # 初始化脚本
│   ├── dev.sh                  # 开发环境
│   └── build.sh                # 构建脚本
│
├── .env.example                # 环境变量模板
├── .gitignore
├── docker-compose.yml
├── Dockerfile
├── requirements.txt
└── README.md
```

### 8.4 关键配置

```bash
# .env.example

# Picovoice
PICOVOICE_ACCESS_KEY=your_access_key_here

# OpenAI
OPENAI_API_KEY=sk-your-openai-key-here

# Anthropic
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Storage
MEMORY_BASE_PATH=~/basic-memory

# API
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=false

# Features
ENABLE_LOCAL_STT=false      # 启用本地STT
ENABLE_VAD=false            # 启用VAD（Phase 2）
ENABLE_BARGE_IN=false      # 启用可打断（Phase 2）
```

---

## 九、下一步行动

### 9.1 立即行动

```
Week 1: 环境搭建
  ├─ 创建项目结构
  ├─ 配置开发环境
  ├─ 设置Git仓库
  └─ 编写基础文档

Week 2-3: 核心功能
  ├─ 唤醒词检测（Porcupine）
  ├─ STT集成（Whisper API）
  ├─ AI对话（Claude）
  └─ TTS播放（OpenAI TTS）

Week 4: 集成测试
  ├─ 端到端流程
  ├─ 错误处理
  ├─ 性能优化
  └─ 用户测试
```

### 9.2 风险与缓解

| 风险 | 概率 | 影响 | 缓解措施 |
|------|------|------|----------|
| API成本超预期 | 中 | 高 | 智能路由、本地备用 |
| Porcupine授权问题 | 低 | 中 | 提前评估openWakeWord |
| 性能瓶颈 | 中 | 中 | 异步优化、缓存 |
| 用户需求变化 | 高 | 中 | 迭代开发、快速响应 |

---

**文档版本历史：**
- v0.1 (2025-12-29): 初始版本，技术栈最终决策
